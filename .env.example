# Whisper Transcription Service - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# API Keys
# =============================================================================

# Anthropic Claude API key for Context7 integration
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx

# Optional: OpenAI API key (if using OpenAI Whisper instead of faster-whisper)
# OPENAI_API_KEY=sk-xxxxxxxxxxxxx

# =============================================================================
# Server Configuration
# =============================================================================

# Application environment (development, production)
ENVIRONMENT=development

# Frontend (Gradio)
FRONTEND_HOST=127.0.0.1
FRONTEND_PORT=7860

# Backend API (FastAPI)
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
BACKEND_RELOAD=True

# Frontend'den Backend'e bağlanmak için URL
BACKEND_URL=http://localhost:8000

# MCP Server configuration
MCP_ENABLED=true
MCP_HOST=localhost
MCP_PORT=8765

# =============================================================================
# Whisper Configuration
# =============================================================================

# Default model size (tiny, base, small, medium, large-v3)
WHISPER_MODEL_SIZE=base

# Device (cuda, cpu)
WHISPER_DEVICE=cuda

# GPU device index (0 for first GPU)
WHISPER_DEVICE_INDEX=0

# Number of parallel workers
WHISPER_NUM_WORKERS=8

# Compute type (float16 for GPU, int8 for CPU)
WHISPER_COMPUTE_TYPE=float16

# Default language (auto, en, tr, etc.)
WHISPER_LANGUAGE=auto

# Enable Voice Activity Detection
WHISPER_VAD_ENABLED=true

# =============================================================================
# Performance & Optimization
# =============================================================================

# Enable TF32 for Ampere+ GPUs
ENABLE_TF32=true

# Maximum file size in MB
MAX_FILE_SIZE=500

# Request timeout in seconds
REQUEST_TIMEOUT=300

# =============================================================================
# Logging
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log file path (optional, leave empty for console only)
# LOG_FILE=logs/whisper.log

# =============================================================================
# Security
# =============================================================================

# Enable CORS (for web API)
ENABLE_CORS=true

# Allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:7860,http://127.0.0.1:7860

# API key for authentication (optional)
# API_KEY=your-secret-api-key

# =============================================================================
# Context7 / AI Features
# =============================================================================

# Enable AI-powered analysis
AI_ANALYSIS_ENABLED=true

# Default Claude model
CLAUDE_MODEL=claude-sonnet-4-5-20250929

# Max tokens for AI responses
CLAUDE_MAX_TOKENS=4096

# =============================================================================
# Storage
# =============================================================================

# Output directory for transcriptions
OUTPUT_DIR=./output

# Temporary files directory
TEMP_DIR=./temp

# Cache directory for models
CACHE_DIR=~/.cache/whisper

# =============================================================================
# Advanced
# =============================================================================

# Enable async processing
ASYNC_ENABLED=true

# Use uvloop for better performance (Linux/Mac only)
USE_UVLOOP=false

# Enable metrics collection
ENABLE_METRICS=false
