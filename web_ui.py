"""
Whisper Streaming - Web ArayÃ¼zÃ¼
Basit ve kullanÄ±cÄ± dostu ses-metin dÃ¶nÃ¼ÅŸtÃ¼rme arayÃ¼zÃ¼
"""

import gradio as gr
import logging
from pathlib import Path
import tempfile
from typing import Tuple, Optional
import time
import os

from whisper_app import WhisperProcessor, WhisperConfig
from gemini_enhancer import GeminiEnhancer


# Logging ayarla
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# Global processor (model Ã¶nbelleÄŸi iÃ§in)
current_processor = None
current_config = None


def format_timestamp(seconds: float) -> str:
    """Saniyeyi okunabilir zaman formatÄ±na Ã§evir (HH:MM:SS)."""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)

    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"


def get_gpu_info() -> str:
    """GPU bilgilerini al."""
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            return f"GPU: {gpu_name} ({gpu_memory:.1f}GB) - {gpu_count} cihaz tespit edildi"
        else:
            return "GPU bulunamadÄ± - CPU modu kullanÄ±lacak"
    except Exception as e:
        return f"GPU bilgisi alÄ±namadÄ±: {e}"


def create_processor(model_size: str, device: str, language: str) -> WhisperProcessor:
    """Processor oluÅŸtur veya mevcut olanÄ± dÃ¶ndÃ¼r."""
    global current_processor, current_config

    # Ayarlar deÄŸiÅŸmediyse mevcut processor'Ä± kullan
    if current_processor is not None:
        if (current_config.model_size == model_size and
            current_config.device == device and
            current_config.language == language):
            logger.info("Mevcut model kullanÄ±lÄ±yor")
            return current_processor

    # Yeni processor oluÅŸtur
    logger.info(f"Yeni model yÃ¼kleniyor: {model_size} ({device})")
    config = WhisperConfig(
        model_size=model_size,
        device=device,
        language=language,
        vac_enabled=True,
        include_timestamps=True,
        num_workers=8,  # Increased workers for better GPU utilization
        device_index=0,  # Primary GPU
    )

    current_config = config
    current_processor = WhisperProcessor(config)

    return current_processor


def transcribe_audio(
    audio_file,
    model_size: str,
    language: str,
    device: str,
    output_format: str,
    use_gemini: bool = False,
    gemini_api_key: Optional[str] = None,
) -> Tuple[str, Optional[str], str]:
    """
    Ses dosyasÄ±nÄ± transkribe et.

    Returns:
        Tuple[transkripsiyon metni, indirilebilir dosya yolu, durum mesajÄ±]
    """
    try:
        if audio_file is None:
            return "", None, "âŒ LÃ¼tfen bir ses dosyasÄ± yÃ¼kleyin!"

        start_time = time.time()

        # Processor oluÅŸtur
        status_msg = f"ğŸ”„ Model yÃ¼kleniyor: {model_size}..."
        logger.info(status_msg)

        processor = create_processor(model_size, device, language)

        # Transkripsiyon yap
        status_msg = "ğŸ¯ Transkripsiyon yapÄ±lÄ±yor..."
        logger.info(f"Ses dosyasÄ± iÅŸleniyor: {audio_file}")

        result = processor.transcribe(Path(audio_file))

        # Ä°ÅŸlem sÃ¼resi
        processing_time = time.time() - start_time

        # Ã‡Ä±ktÄ± formatÄ±na gÃ¶re dosya oluÅŸtur
        output_file = None

        if output_format == "Text (.txt)":
            # Text dosyasÄ± oluÅŸtur
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt', encoding='utf-8') as f:
                f.write(result.full_text)
                output_file = f.name

        elif output_format == "JSON (.json)":
            # JSON dosyasÄ± oluÅŸtur
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json', encoding='utf-8') as f:
                result.to_json(Path(f.name))
                output_file = f.name

        elif output_format == "AltyazÄ± (.srt)":
            # SRT dosyasÄ± oluÅŸtur
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.srt', encoding='utf-8') as f:
                result.to_srt(Path(f.name))
                output_file = f.name

        # Gemini ile metin iyileÅŸtirme (opsiyonel)
        enhanced_text = ""
        gemini_status = ""
        if use_gemini:
            try:
                logger.info("ğŸ¤– Gemini API ile metin iyileÅŸtiriliyor...")
                enhancer = GeminiEnhancer(api_key=gemini_api_key)
                enhanced_text = enhancer.enhance_transcript(
                    result.full_text,
                    language=language
                )
                gemini_status = "âœ“ UygulandÄ±"
                logger.info("âœ“ Gemini iyileÅŸtirme tamamlandÄ±")
            except ValueError as e:
                logger.warning(f"Gemini API anahtarÄ± hatasÄ±: {e}")
                gemini_status = "âœ— API anahtarÄ± eksik"
            except Exception as e:
                logger.warning(f"Gemini iyileÅŸtirme hatasÄ±: {e}")
                gemini_status = "âœ— Hata oluÅŸtu"
        else:
            gemini_status = "âœ— KullanÄ±lmadÄ±"
        
        # Zaman bazlÄ± segment Ã§Ä±ktÄ±sÄ± oluÅŸtur (orijinal)
        formatted_text = ""
        for segment in result.segments:
            start_time = format_timestamp(segment.start)
            end_time = format_timestamp(segment.end)
            formatted_text += f"[{start_time} - {end_time}] {segment.text.strip()}\n\n"

        # BaÅŸarÄ± mesajÄ±
        status_msg = f"""
âœ… **Transkripsiyon TamamlandÄ±!**

ğŸ“Š **Ä°statistikler:**
- **Dil:** {result.language.upper()}
- **SÃ¼re:** {result.duration:.2f} saniye
- **Ä°ÅŸlem SÃ¼resi:** {processing_time:.2f} saniye
- **HÄ±z:** {result.duration/processing_time:.2f}x gerÃ§ek zamanlÄ±
- **Segment SayÄ±sÄ±:** {len(result.segments)}
- **Model:** {model_size}
- **Cihaz:** {device.upper()}
- **Gemini Ä°yileÅŸtirme:** {gemini_status}

ğŸ’¡ **Ä°pucu:** DosyayÄ± indirmek iÃ§in aÅŸaÄŸÄ±daki "Ä°ndir" butonuna tÄ±klayÄ±n.
        """

        # Gemini kullanÄ±ldÄ±ysa iyileÅŸtirilmiÅŸ metni gÃ¶ster, deÄŸilse orijinali
        display_text = enhanced_text if (use_gemini and enhanced_text) else formatted_text.strip()
        
        return display_text, output_file, status_msg

    except Exception as e:
        logger.error(f"Hata: {e}", exc_info=True)
        error_msg = f"""
âŒ **Hata OluÅŸtu!**

**Hata MesajÄ±:** {str(e)}

**OlasÄ± Ã‡Ã¶zÃ¼mler:**
- GPU hatasÄ± alÄ±yorsanÄ±z, "CPU" modunu seÃ§in
- Bellek hatasÄ± alÄ±yorsanÄ±z, daha kÃ¼Ã§Ã¼k bir model seÃ§in (tiny veya base)
- Ses dosyasÄ± formatÄ±nÄ± kontrol edin
        """
        return "", None, error_msg


# Gradio arayÃ¼zÃ¼
def create_ui():
    """Gradio arayÃ¼zÃ¼ oluÅŸtur."""

    with gr.Blocks(
        title="Whisper Transkripsiyon",
        theme=gr.themes.Soft(),
    ) as demo:

        # GPU bilgisini al
        gpu_info = get_gpu_info()

        gr.Markdown(f"""
        # ğŸ™ï¸ Whisper Ses-Metin DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼

        Ses dosyalarÄ±nÄ±zÄ± metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n. MP3, WAV, M4A, FLAC formatlarÄ± desteklenir.

        **ğŸ’» Sistem:** {gpu_info}
        """)

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ Ses DosyasÄ± YÃ¼kle")

                audio_input = gr.Audio(
                    label="Ses DosyasÄ±",
                    type="filepath",
                    sources=["upload", "microphone"],
                )

                gr.Markdown("### âš™ï¸ Ayarlar")

                model_dropdown = gr.Dropdown(
                    choices=[
                        "tiny",
                        "base",
                        "small",
                        "medium",
                        "large-v3",
                        "turbo",
                    ],
                    value="small",
                    label="Model",
                    info="TÃ¼rkÃ§e iÃ§in en az 'small' model Ã¶nerilir (daha iyi noktalama)"
                )

                language_dropdown = gr.Dropdown(
                    choices=[
                        "auto (Otomatik AlgÄ±la)",
                        "tr (TÃ¼rkÃ§e)",
                        "en (Ä°ngilizce)",
                        "de (Almanca)",
                        "fr (FransÄ±zca)",
                        "es (Ä°spanyolca)",
                        "it (Ä°talyanca)",
                        "ar (ArapÃ§a)",
                        "ru (RusÃ§a)",
                        "zh (Ã‡ince)",
                    ],
                    value="auto (Otomatik AlgÄ±la)",
                    label="Dil",
                    info="VarsayÄ±lan: Otomatik algÄ±lama"
                )

                device_dropdown = gr.Dropdown(
                    choices=["cuda (GPU)", "cpu (CPU)"],
                    value="cuda (GPU)",
                    label="Ä°ÅŸlemci",
                    info="GPU varsa 5-10x daha hÄ±zlÄ±"
                )

                output_format_dropdown = gr.Dropdown(
                    choices=[
                        "Text (.txt)",
                        "JSON (.json)",
                        "AltyazÄ± (.srt)",
                    ],
                    value="Text (.txt)",
                    label="Ã‡Ä±ktÄ± FormatÄ±",
                    info="Ä°ndirilecek dosya formatÄ±"
                )
                
                gr.Markdown("### ğŸ¤– Gemini AI Ä°yileÅŸtirme (Opsiyonel)")
                
                gemini_checkbox = gr.Checkbox(
                    label="Gemini ile Metin Ä°yileÅŸtir",
                    value=False,
                    info="Noktalama, dilbilgisi ve akÄ±cÄ±lÄ±k iyileÅŸtirmesi"
                )
                
                gemini_api_key_input = gr.Textbox(
                    label="Gemini API AnahtarÄ±",
                    placeholder="API anahtarÄ±nÄ±zÄ± buraya girin (veya GEMINI_API_KEY ortam deÄŸiÅŸkeni)",
                    type="password",
                    visible=False
                )
                
                # Checkbox deÄŸiÅŸtiÄŸinde API key input'unu gÃ¶ster/gizle
                def toggle_api_key(use_gemini):
                    return gr.update(visible=use_gemini)
                
                gemini_checkbox.change(
                    fn=toggle_api_key,
                    inputs=[gemini_checkbox],
                    outputs=[gemini_api_key_input]
                )

                transcribe_btn = gr.Button(
                    "ğŸš€ Transkribe Et",
                    variant="primary",
                    size="lg"
                )

            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ Transkripsiyon Sonucu")

                status_output = gr.Markdown(
                    value="â³ Ses dosyasÄ± yÃ¼kleyip 'Transkribe Et' butonuna basÄ±n...",
                )

                text_output = gr.Textbox(
                    label="Metin",
                    lines=15,
                    placeholder="Transkripsiyon burada gÃ¶rÃ¼necek...",
                    show_copy_button=True,
                )

                file_output = gr.File(
                    label="ğŸ’¾ DosyayÄ± Ä°ndir",
                )

        gr.Markdown("""
        ---
        ### ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

        | Model | HÄ±z | Kalite | GPU Bellek | KullanÄ±m |
        |-------|-----|--------|------------|----------|
        | tiny | âš¡âš¡âš¡âš¡âš¡ | â­â­ | ~1GB | HÄ±zlÄ± test |
        | base | âš¡âš¡âš¡âš¡ | â­â­â­ | ~1GB | GÃ¼nlÃ¼k kullanÄ±m |
        | small | âš¡âš¡â­ | â­â­â­â­ | ~2GB | Ä°yi kalite |
        | medium | âš¡âš¡ | â­â­â­â­â­ | ~5GB | YÃ¼ksek kalite |
        | large-v3 | âš¡ | â­â­â­â­â­ | ~10GB | En iyi kalite |
        | turbo | âš¡âš¡âš¡âš¡ | â­â­â­â­â­ | ~6GB | Optimize edilmiÅŸ (large-v3) |

        ### ğŸ’¡ Ä°puÃ§larÄ±
        - **Ä°lk kullanÄ±mda** model indirilecektir, biraz zaman alabilir
        - **GPU yoksa** CPU modunu seÃ§in (daha yavaÅŸ ama Ã§alÄ±ÅŸÄ±r)
        - **Bellek hatasÄ±** alÄ±rsanÄ±z daha kÃ¼Ã§Ã¼k model deneyin
        - **Otomatik dil algÄ±lama** Ã§oÄŸu durumda iyi Ã§alÄ±ÅŸÄ±r
        - **turbo modeli** large-v3'Ã¼n optimize edilmiÅŸ versiyonudur (8x daha hÄ±zlÄ±)
        - **TÃ¼rkÃ§e iÃ§in** en az 'small' model kullanÄ±n (daha iyi noktalama ve dilbilgisi)
        - **Dili manuel seÃ§in** (tr) otomatik algÄ±lama yerine daha iyi sonuÃ§ iÃ§in
        
        ### ğŸ¤– Gemini Ä°yileÅŸtirme
        - **Gemini API** transkripsiyon sonrasÄ± metni akÄ±cÄ±laÅŸtÄ±rÄ±r ve dÃ¼zeltir
        - **API anahtarÄ±** iÃ§in: https://makersuite.google.com/app/apikey
        - **GEMINI_API_KEY** ortam deÄŸiÅŸkeni ayarlarsanÄ±z her seferinde girmek zorunda kalmazsÄ±nÄ±z
        - Gemini kullanÄ±mÄ± **opsiyonel**dir, checkbox'Ä± iÅŸaretlemeyin normal transkripsiyon iÃ§in

        ### âš¡ GPU OptimizasyonlarÄ± (Otomatik Aktif)
        - **TF32 desteÄŸi** - Ampere+ GPU'larda %20 daha hÄ±zlÄ±
        - **float16 precision** - Bellek kullanÄ±mÄ±nÄ± yarÄ±ya indirir
        - **CUDA cache** - Model yeniden yÃ¼klemeyi Ã¶nler

        ### ğŸ¯ Desteklenen Formatlar
        - **Ses:** MP3, WAV, M4A, FLAC, OGG
        - **Ã‡Ä±ktÄ±:** TXT (dÃ¼z metin), JSON (detaylÄ±), SRT (altyazÄ±)
        """)

        # Event handler
        def process_transcription(audio, model, lang, device, format, use_gemini, api_key):
            # Dil kodunu ayÄ±kla
            lang_code = lang.split("(")[0].strip()
            if lang_code == "auto":
                lang_code = "auto"

            # Cihaz kodunu ayÄ±kla
            device_code = device.split("(")[0].strip()

            return transcribe_audio(
                audio, 
                model, 
                lang_code, 
                device_code, 
                format,
                use_gemini=use_gemini,
                gemini_api_key=api_key if api_key else None
            )

        transcribe_btn.click(
            fn=process_transcription,
            inputs=[
                audio_input,
                model_dropdown,
                language_dropdown,
                device_dropdown,
                output_format_dropdown,
                gemini_checkbox,
                gemini_api_key_input,
            ],
            outputs=[text_output, file_output, status_output],
        )

        # Ã–rnek sesler (opsiyonel)
        gr.Markdown("""
        ---
        ### ğŸ¤ NasÄ±l KullanÄ±lÄ±r?
        1. Ses dosyanÄ±zÄ± yÃ¼kleyin (veya mikrofon ile kaydedin)
        2. Model ve dil seÃ§eneklerini ayarlayÄ±n
        3. "Transkribe Et" butonuna basÄ±n
        4. Sonucu gÃ¶rÃ¼ntÃ¼leyin ve indirin
        """)

    return demo


def main():
    """Ana fonksiyon."""

    # Set UTF-8 encoding for Windows console
    import sys
    if sys.platform == 'win32':
        try:
            sys.stdout.reconfigure(encoding='utf-8')
        except:
            pass

    print("\n" + "="*70)
    print(" WHISPER TRANSKRIPSIYON WEB ARAYUZU ".center(70, "="))
    print("="*70 + "\n")

    print(">> Web arayuzu baslatiliyor...")
    print(">> Tarayicinizda otomatik olarak acilacak")
    print(">> Kapatmak icin Ctrl+C basin\n")

    # ArayÃ¼zÃ¼ oluÅŸtur ve baÅŸlat
    demo = create_ui()

    demo.launch(
        server_name="127.0.0.1",  # Localhost
        server_port=7865,          # Daha yÃ¼ksek port
        share=False,               # Genel paylaÅŸÄ±m kapalÄ±
        inbrowser=True,            # TarayÄ±cÄ±da otomatik aÃ§
        show_error=True,           # HatalarÄ± gÃ¶ster
    )


if __name__ == "__main__":
    main()
